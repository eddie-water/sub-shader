{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Acceleration Basics 03\n",
    "This notebook follows the video Python CUDA Installation & CUPY | GPU Acceleration Basics 03 by Rounak Paul found on YouTube.\n",
    "\n",
    "## GPU Memory\n",
    "The code below demonstrates the use of CUDA with Numba to do matrix multiplication using both global and shared memory. The first part shows a simple element-wise addition of two arrays, while the second part demonstrates a more complex matrix multiplication using shared memory for optimization. The results are verified against Python's built-in matrix multiplication to ensure correctness. The use of shared memory can significantly improve performance for large matrices  reduces the number of global memory accesses and allows for faster data sharing between threads within a block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda, float32\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def foo(a, b, c):\n",
    "    pos = cuda.grid(1)\n",
    "    size =  len(c)\n",
    "\n",
    "    if pos < size:\n",
    "        c[pos] = a[pos] + b[pos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "a = cuda.to_device(np.random.random(N))\n",
    "b = cuda.to_device(np.random.random(N))\n",
    "c = cuda.device_array_like(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, 'forall()' creas a 1D grid for a given data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.04683472, 0.6329102 , 0.26522472, ..., 0.30387198, 0.83543071,\n",
       "       1.21570496], shape=(100000,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.forall(len(a))(a, b, c)\n",
    "c.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.04683472, 0.6329102 , 0.26522472, ..., 0.30387198, 0.83543071,\n",
       "       1.21570496], shape=(100000,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nthreads = 256\n",
    "nblocks = (len(a) // nthreads) + 1\n",
    "foo[nblocks, nthreads](a, b, c)\n",
    "c.copy_to_host()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matrix_mult(A, B, C):\n",
    "    # Perform square matrix multiplication C = A * B\n",
    "    i, j = cuda.grid(2)\n",
    "\n",
    "    # This condition is necessary to avoid accessing out of bounds\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        for k in range(A.shape[1]):\n",
    "            C[i, j] += A[i, k] * B[k, j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_h = np.arange(16).reshape([4, 4])\n",
    "y_h = np.ones([4, 4])\n",
    "z_h = np.zeros([4, 4])\n",
    "\n",
    "x_d = cuda.to_device(x_h)\n",
    "y_d = cuda.to_device(y_h)\n",
    "z_d = cuda.to_device(z_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpb = (16, 16)\n",
    "bpg_x = math.ceil(z_h.shape[0] / tpb[0])\n",
    "bpg_y = math.ceil(z_h.shape[1] / tpb[1])\n",
    "bpg = (bpg_x, bpg_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eddie-water/dev/python/sub-shader/env/lib/python3.12/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "matrix_mult[bpg, tpb](x_d, y_d, z_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Z = X * Y\n",
      " [[ 6.  6.  6.  6.]\n",
      " [22. 22. 22. 22.]\n",
      " [38. 38. 38. 38.]\n",
      " [54. 54. 54. 54.]]\n"
     ]
    }
   ],
   "source": [
    "z_h = z_d.copy_to_host()\n",
    "print(\"Result of Z = X * Y\\n\", z_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication - Improved with Shared Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPB = 16\n",
    "\n",
    "@cuda.jit\n",
    "def fast_matrix_mult(A, B, C):\n",
    "    # Define an array in shared memory\n",
    "    sA = cuda.shared.array((TPB, TPB), dtype=float32)\n",
    "    sB = cuda.shared.array((TPB, TPB), dtype=float32)\n",
    "\n",
    "    # Get the row and column index of the C element\n",
    "    x, y = cuda.grid(2)\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    bpg = cuda.gridDim.x\n",
    "    \n",
    "    temp = float32(0.0)\n",
    "\n",
    "    for i in range(bpg):\n",
    "        # Preload data into shared memory\n",
    "        sA[tx, ty] = 0\n",
    "        sB[tx, ty] = 0\n",
    "        if (x < A.shape[0]) and ((tx + i * TPB) < A.shape[1]):\n",
    "            sA[ty, tx] = A[y, tx + i * TPB]\n",
    "        if (y < B.shape[1]) and ((ty + i * TPB) < B.shape[0]):\n",
    "            sB[ty, tx] = B[ty + i * TPB , x]\n",
    "\n",
    "        # Synchronize to ensure all threads have loaded the data\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Perform the multiplication\n",
    "        for j in range(TPB):\n",
    "            temp += sA[ty, j] * sB[j, tx]\n",
    "\n",
    "        # Synchronize to ensure all threads have completed the mults\n",
    "        cuda.syncthreads()\n",
    "    \n",
    "    if y < C.shape[0] and x < C.shape[1]:\n",
    "        C[y, x] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialize the matrices\n",
    "x_h = np.arange(16).reshape([4, 4])\n",
    "y_h = np.ones([4, 4])\n",
    "z_h = np.zeros([4, 4])\n",
    "\n",
    "x_d = cuda.to_device(x_h)\n",
    "y_d = cuda.to_device(y_h)\n",
    "z_d = cuda.to_device(z_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpb = (TPB, TPB)\n",
    "bpg_x = math.ceil(z_h.shape[0] / tpb[0])\n",
    "bpg_y = math.ceil(z_h.shape[1] / tpb[1])\n",
    "bpg = (bpg_x, bpg_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Z = X * Y with shared memory\n",
      " [[ 6.  6.  6.  6.]\n",
      " [22. 22. 22. 22.]\n",
      " [38. 38. 38. 38.]\n",
      " [54. 54. 54. 54.]]\n",
      "\n",
      "Same result as Python's built-in matrix multiplication? : True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eddie-water/dev/python/sub-shader/env/lib/python3.12/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "fast_matrix_mult[bpg, tpb](x_d, y_d, z_d)\n",
    "z_h = z_d.copy_to_host()\n",
    "\n",
    "print(\"Result of Z = X * Y with shared memory\\n\", z_h)\n",
    "print()\n",
    "print(\"Same result as Python's built-in matrix multiplication? :\", np.allclose(z_h, x_h @ y_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.9 μs ± 3.54 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "20.5 μs ± 568 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "\n",
      "The Shared Memory method is on average 1.00 times faster\n"
     ]
    }
   ],
   "source": [
    "# Reinitialize the matrices\n",
    "x_h = np.arange(16).reshape([4, 4])\n",
    "y_h = np.ones([4, 4])\n",
    "z_h = np.zeros([4, 4])\n",
    "\n",
    "x_d = cuda.to_device(x_h)\n",
    "y_d = cuda.to_device(y_h)\n",
    "z_d = cuda.to_device(z_h)\n",
    "\n",
    "t_original = %timeit -o matrix_mult[bpg, tpb](x_d, y_d, z_d)\n",
    "\n",
    "# Reinitialize the matrices\n",
    "x_h = np.arange(16).reshape([4, 4])\n",
    "y_h = np.ones([4, 4])\n",
    "z_h = np.zeros([4, 4])\n",
    "\n",
    "x_d = cuda.to_device(x_h)\n",
    "y_d = cuda.to_device(y_h)\n",
    "z_d = cuda.to_device(z_h)\n",
    "t_shared_mem = %timeit -o fast_matrix_mult[bpg, tpb](x_d, y_d, z_d)\n",
    "\n",
    "t_ratio_avg = t_original.average / t_original.average\n",
    "\n",
    "print()\n",
    "print(f\"The Shared Memory method is on average {t_ratio_avg:.2f} times faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "Well it looks like we got worse performance. So cool!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
