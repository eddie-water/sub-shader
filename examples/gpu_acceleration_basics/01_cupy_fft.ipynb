{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Acceleration Basics 01\n",
    "This notebook follows the video Python CUDA Installation & CUPY | GPU Acceleration Basics 01 by Rounak Paul found on YouTube.\n",
    "\n",
    "## GPU Acceleration of Simple / Small Computions \n",
    "NumPy runs on the CPU, CuPy runs on the GPU. For simple computations, it's not really worth it. As you can see, the GPU is so much slower than the CPU. The guy in the video said it's called the \"Acceleration Tax\". Data transfer is not the main concern here. Our data x_dev has already been stored in the device memory. \n",
    "\n",
    "He mentions a metaphor of a race car (CPU) vs a bus (GPU). The clocks of a CPU vs GPU is something like 5 Ghz vs 1.5 GHz. When the task is small and simple enough, the CPU will always beat the GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array stored on host memory aka the CPU\n",
    "x_host = np.array([1, 2, 3])\n",
    "type(x_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cupy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array on the device memory aka the GPU\n",
    "x_dev = cp.array([1, 2, 3])\n",
    "type(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.06 μs ± 7.13 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.linalg.norm(x_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 μs ± 432 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cp.linalg.norm(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "source": [
    "# List all of the GPUs I have access to:\n",
    "num_gpus = cp.cuda.runtime.getDeviceCount()\n",
    "\n",
    "for i in range(num_gpus):\n",
    "    props = cp.cuda.runtime.getDeviceProperties(i)\n",
    "    print(f\"GPU {i}: {props['name'].decode()}\")\n",
    "\n",
    "# Select which GPU you want to put the CuPy array\n",
    "with cp.cuda.Device(0):\n",
    "    x_on_device_0 = cp.array([1, 2, 3, 4, 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NumPy array on host\n",
    "x_host = np.random.randint(0, 255, (20000, 20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer NumPy array from host to device\n",
    "x_dev = cp.asarray(x_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer CuPy array from device to host\n",
    "x_host_1 = x_dev.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Acceleration of the Fast Fourier Transform\n",
    "SciPy naturally runs on the CPU. The SciPy GPU wrapper is in cupyx, the experimental CuPy library. \n",
    "\n",
    "Also it is a good habit it free the object in VRAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU FFT\n",
    "from scipy.fft import fftn\n",
    "\n",
    "# CUDA implementation of some algorithms\n",
    "import cupyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.64 s ± 1.1 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "The slowest run took 7.92 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "66.2 μs ± 74.3 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "The acceleration is on average 54953.44 times faster\n"
     ]
    }
   ],
   "source": [
    "# Benchmark the acceleration\n",
    "t_host = %timeit -o fftn(x_host)\n",
    "t_dev = %timeit -o cupyx.scipy.fft.fftn(x_dev)\n",
    "\n",
    "t_ratio_best = t_host.best / t_dev.best\n",
    "t_ratio_avg = t_host.average / t_dev.average\n",
    "t_ratio_stdev = t_host.stdev / t_dev.stdev\n",
    "\n",
    "print()\n",
    "print(f\"The acceleration is on average {t_ratio_avg:.2f} times faster\")\n",
    "\n",
    "# Free VRAM objects\n",
    "cp.get_default_memory_pool().free_all_blocks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
